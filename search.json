[{"title":"关于项目管理的一些总结和思考","path":"/2024/09/10/关于项目管理的一些总结和思考/","content":"一、前言——从流程至下到流程至上最近从互联网跳槽到一家小国企，发现这里的项目管理和互联网差异很大，因此想把最近的思考和感悟记录一下。在互联网时，我曾抱怨过：这流程怎么这么重，预审、评审、对齐、站会、复盘，如果没有那么多流程，每天可以安心写代码该有多好。同事们常常调侃“白天扯皮，晚上写代码”，也总是吐槽“有些人只对方案不写代码，可真轻松”。来到这家国企后发现这里几乎没有流程，需求对完就开始写代码，缺什么字段少什么方法，自己加完再告诉对接人就好。不过这样的开发方式似乎并不像预想的那么美好，流程缺失后发现扯的皮好像更多了，并且扯完还总是返工。所以如果你觉得流程不重要，那你一定没有经历过没有流程的项目。不过项目管理是一个大而泛的概念，我想结合我的经历过的一些小场景去作总结归纳，阐述流程的重要性，而不是体系化的描述什么是项目管理，怎么做项目管理（当然以我的工作经验，似乎也还达不到这一点），避免大而空 二、一些常见的困境困境一：屁股决定脑袋“业务只给怎么点时间，怎么能保证质量”；“这个接口的参数定义对前端很不友好”；“产品想怎么改就怎么改，完全不考虑好不好实现”；“这个功能逻辑清晰交互简单怎么开发就实现不了呢”；“你这个改动点为什么没通知测试回归”；“这个功能不应该放在我的域”。这些话你应该自己说过又或者听别人说过，显然这些都出自不同角色的口吻：前端、后端、业务、测试，每个角色都对其他角色有一些误解，由于不同角色带来的思维惯性影响，这些角色总是聊不到一块，总是在相互吐槽；同一角色之中不同团队不同领域也总是会存在分歧 困境二：人多力量小？“这么简单的模块，换我来做，半天就搞定了，怎么他要这么久呢？“在与其他项目成员、外部团队对接时，我产生过这样的想法，如果是一个比较小的项目，我甚至会想，这个项目如果交给我一个人去做，也许都要不了那么久，那样我可以随心所欲的按照自己的想法设计。人多本应力量大，但似乎人越多做起事情来越麻烦效率越低 困境三：到底应该找谁？在有的项目中，在交互的团队比较多，或者一个团队中涉及多个开发人员时，常常会遇到需要找人对接问题时，总是甩来甩去，A说应该找B，B说应该找C，C说我不清楚这个事情；又或者原本划定由A负责，但找到他时却说已经交接给B了，找到B时，B只清楚概要不清楚细节。这些扯皮总是不断拖慢项目节奏 困境四：结论到底是什么？“这个功能到底应该怎么实现？之前你说的是要这样做，但现在又说要这样做”这是我最近常常听到的话，对接方的结论总是反复横跳前后不一致，我们也总是不断地改写已经测完的代码 困境五、需求频繁变更如果是产品中途改需求，有时还可以跟产品讨价还价，放到迭代中上线，最让人头疼的是已经开发到一半时，上游系统让下游系统加新的接口&#x2F;MQ，因为这往往意味着当前的方案有漏洞，存在交互、依赖被遗漏掉了，又或者是方案根本没有对齐，那如果我们不满足上游系统的要求，很可能流程就无法闭环。 三、我们能做什么？我本想针对每种困境单独列一列应对措施，但思来想去觉得每种情况的解决方式并不是单一的，每种应对措施也会对多种困境起到效果，因此我想还是按照措施逐个梳理，如果某种做法对上述场景有针对性效果的，我也会在文中点出 1、标准化评审流程上面提到的困境我常会遇到，也不难发现，很多困境的核心，尤其是困境一，来自于我们对人（能力、做事风格、设计风格，期望）、对事（复杂度、可行性）的错误评估，我们需要借助一些标准化的动作——“评审”来收束评估过程（收束这个词可能很怪，不过我觉得每个人的思维习惯不一致，我们不可能通过任何方法让每个的思考过程和结果都一致，因此只能借助标准化的流程让人们思考的集中在我们期望的范围内，因此我想收束一词是合适的）。 通常在项目管理过程中，我们会经历很多次评审——需求预审评审、概要设计评审、详细设计评审、代码评审、测试用例评审、上线方案评审等等，每一个环节都旨在帮助我们更好的把握的人和事，打通不同角色、不同领域之间的隔阂。 1.1、需求评审预审首先在需求预审评审阶段钱，通常需要业务、产品先输出一份项目文档和若干需求文档，当进入预审阶段，PM需要根据文档识别出可能涉及到的模块，或者更标准的说法——干系人识别（不过大多数时候产品在出这些文档之前，应该已经和各自模块的技术负责人简单聊过，清楚自己的需求大致涉及哪些模块的开发），并通知各模块owner审阅文档，标注不清晰、存在争议的地方，比如用词不准确（比如描述订单走到终态，取消包不包含）、只有概念没有定义、缺失异常场景的交互（某个模块渲染失败直接报错还是隐藏）、流程不完整、前后流程矛盾等。此外如果owner发现分到的内容并不全部属于自己的模块，还需要PM和该owner共同讨论重新划分领域，识别出新的owner。同时业务和产品需要重新思考被标注的内容，也许还需要重新找各模块owner聊一聊。当这些事情都做完之后，就可以召集业务、各模块产品、owner拉会评审，由业务方首先进行流程串讲，然后各个模块产品依此讲解需求，并由模块owner、开发、测试提出问题，小问题应该当场得出结论，大问题由PM记录并在会后跟进，必要时进行二次评审（通常不应该超过两次）。 1.2、概要设计评审在需求确认清楚后，需要PM&#x2F;架构师（如果项目有架构师，架构师来做更合理）输出概要设计，概要设计的作用主要是拆解功能点、划分领域、串联流程，可以使用思维导图、架构图、时序图、协作图等工具。在这个过程中，PM和架构师需要和各模块owner进行充分的交流，了解各模块的期望和原则（每个模块在方案设计上可能会有一些原则，我曾常听到类似于这些话：“XX系统的定位是XX，不应该做XX功能”，“XX模块是通用模块，不做定制，应该在上层做”。因此提前了解各模块的原则很重要） 这里你可能会想，明明在评审阶段我们已经做过了领域模块的划分，为什么这里还会涉及？首先通常在需求评审阶段所做的领域划分会比较粗糙（因为此时的需求是粗糙的），在需求确定后往往还需要做一些调整；其次可能会遇到某些功能既可以放在A领域也可以放在B领域，这时就需要架构师来考虑到底放在哪个领域更合理；再者概要设计阶段的领域划分应该更加细化，例如画出每个领域内部可能还存在某些子模块，这些子模块之间、子模块和外部领域之间如何交互。 当概要设计完成后，需要PM、架构师组织与各模块owner评审确认，尤其是确认领域的划分和交互流程上是否存在争议，如果存在争议，则需要及时调整概要设计。 此外，在概要设计评审阶段可能还需要做一下依赖识别，在系统之间交互较多的项目中，可能很多模块都涉及新增接口调用或mq，这些新增的依赖我们需要尽早将它们识别出来，并确定好提供时间，否则日后可能会成为交付的瓶颈。当然在概要设计阶段可能无法全部识别出来，不过PM&#x2F;架构师可以提供一个表格让各模块填写，包括需求方、依赖内容、被依赖方、提供时间等等，在概要设计阶段这张表格应当被尽可能多的填写并由双方确认，剩余的也应当在详细设计评审完成前确认完成。 1.3、详细设计评审概要设计定义好边界和交互后，就需要各owner对各自模块的设计进行细化，包括内部模型设计、api设计、灰度方案设计、影响面评估等等，这些设计应当是具体实现的体现，即开发对照着这份详细设计应该就能知道要如何编码，测试也应该能结合这份设计文档去写测试用例。 通常在一个大项目中，可能会涉及很多团队，因此通常没有必要组织统一的详细设计评审，各个团队内部在规定的时间内组织完成即可。不过作为PM可以让各团队将详细设计统一放到项目空间同一目录下，方便查阅，同时我们也可以和架构师一起翻阅一遍，看一看大方向是否有问题 1.4、代码评审很多团队会因为任务重时间紧就忽略代码评审，这种做法并不值得推荐，尤其是在风险较大的项目中，我曾遇到过有人代码中存在较大漏洞经评审后需要打回大改的，这样的代码如果未经评审直接带到线上，可想而知是多恐怖的事情。 代码评审最重要的是要关注代码实现的正确性，但是参与代码评审的人员很可能并不完全了解该项目的背景，因此讲述者应该先介绍项目背景和所做的功能。不过即使事先讲述背景，参与这也无法识别出代码中的所有风险，因此大多数时候评审可能还会关注规范性、健壮性和可扩展性三个方面。 规范性：通常优秀的团队应该有自己的代码规范，如果没有，也可以参照阿里编码规范，检查命名是否合理、是否有npe、魔法数字、过深的嵌套、过长的方法等等 健壮性：主要关注异常场景的处理，例如调用外部接口的强弱依赖、页面模块渲染的强弱依赖、主从库方法使用是否合理（高qps场景不应该查主库、高实时性场景不应该查从库）等 可扩展性：主要关注业务组件和方法的抽象，是不是存在分层混乱、业务逻辑交叉、抽象程度不够等情况 1.5、测试用例评审测试是质量的最后一道防线，曾经我所在的团队有一条铁律——严禁任何未经测试的代码带上线，做到这一点并不容易，因此产品、研发和测试三方打破隔阂异常重要。 测试人员通常会在技术方案评审完后，提测之前编写测试用例并拉产品和研发一起评审，测试用例通常是根据需求文档和技术方案来编写的，因此在用例评审的过程中，需要确认测试用例的描述是否与需求、实现一致，是否有遗漏的点。这个过程中最重要的是研发必须要清醒的意识到自己改动了什么，对线上环境抱有敬畏之心，每一行代码的改动都可能带来意想不到的问题，代码对于测试来说是黑盒，仅凭需求文档和技术方案，测试不可能识别出一些刁钻的改动，因此研发的每一项改动，哪怕你认为无关紧要，都应该同步到测试，并由测试确认回归面（我曾见过一些研发在改代码时“顺手”优化了一行他认为不合理的点，但这个优化没有自测也没有同步给测试，上线后出现问题）。 1.6、上线方案评审上线是一件劳心又劳力的工作，并且也伴随着巨大的风险，因此必须要做好方案设计和评估。通常需要关注几个点：容量评估与资源准备、配置准备、发布批次和灰度计划、回滚计划、线上验证计划 容量评估与资源准备：新的功能意味着新的流量，我们需要提前评估上线后各个系统的流量，并提前准备好扩容。通常这个流量的评估可以依据现有的日活用户数、功能入口页的qps和目标系统的资源水位来评估，例如本次项目在应用首页增加了一个权益查询，当前首页的高峰期qps在20000，约有20%的日活用户满足漏出该入口的条件，那么点击该入口后进入的页面预计高峰期会有4000（通常会小于，因为不可能所有用户同时点进该页面，但还是应该做好最坏的准备），那么这个新页面查询的所有接口包括下游系统的rpc接口，都可能会新增4000的qps（对于下游系统，通常未必，因为可能会有前置条件阻断了进入下游的流量，因此这需要上游去评估可能对下游带来的增量），这些系统、以及涉及的存储，都需要去关注当前的配置能否承担这些流量增量。 配置准备：新增的功能通常也会涉及新增的配置，例如mq生产者组消费者组、数据库表变更、配置中心的配置等等，其中有些配置可能需要在发布前配好，有些则需要再全量后配置，我们需要提前列出所有的配置和他们的完成时期。 发布批次和灰度计划：对于后端系统来说，上线前还需要考虑是否需要放到一个灰度组中发布，对于有些功能，可能上线后立即需要白名单验证，那通常需要放入到一个灰度组中一起发布，否则可能出现流量走到生产机器中出现异常（不过这也取决于灰度系统是如何设计的）。但放入同一个灰度组也有风险，如果灰度组中的一个系统出现异常，灰度组中的所有系统都需要回滚重发。因此通常如果有灰度验证要求，通常应放入一个灰度组，如果没有，各模块单独灰度可能更好。对于前端系统来说，也需要考虑一下什么时机发布，如果是全新的页面，并且入口由后端控制，那么在后端开始灰度时就可以发布；如果是在原有的页面上修改，那还需要考虑一下是否需要等后端全量后再发布（例如后端可能会有一些版本控制逻辑，在没有全量前前端发布可能导致走到生产流量的用户拉不起来某个新做的组件） 回滚计划：上线后我们还需要考虑出现问题时如何处理，通常最粗暴的方法是回滚，但回滚并不适用于所有场景，对于一些新老流程迭代的项目，在进入灰度后可能已经有些用户走入了新流程，这时候回滚可能会导致这部分用户流程走不下去，因此通常需要有一个总的功能开关，各个子功能入口也应当有单独的开关，当问题发生后立刻关闭开关，先保证不会有新流量进入到异常的流程，同时拉新的分治修复问题上线，并同步拉取错误数据进行修复，并在这两项都完成后重新打开开关观察。 线上验证计划：上线后通常还需要进行线上流程验证，这需要关注可验证时机、验证数据准备和覆盖场景。首先可验证时间，例如灰度期间验证或者全量后验证，不同的验证时机对发布批次灰度计划提出了要求，因此需要提前和测试、研发沟通确认。其次验证数据准备，通常必须要做的是各个系统添加白名单，另外还需要做一些特定的准备，例如开通测试钱包、发放测试优惠券等等。最后还需要确定好覆盖场景，线上通常不是所有场景都能验证到。例如有些功能需要验证轨迹真实性，有些场景需要再第三方系统下单并走到完成，这通常是无法具备的，因此线上验证计划中需要标明哪些场景可以测那些不可以，哪些必须测哪些只需要观察数据 PM在发布前几天通常需要提前核对以上几项，在项目空间中建立文档并让各团队各角色罗列发布涉及的系统、配置、资源申请，以及灰度计划、回滚计划、验证计划，并拉会评审。不过有些事情其实可以放到前面去做，例如白名单、开关应当在提测前准备好，测试也需要去验证这些是否能起作用。这些事项罗列完成后，在上线前、灰度后、全量后、打开开关前几个阶段还需要再去检查每一个事项的完成情况。 1.7、总结看完了上述评审过程，不难发现这些评审过程其实并不能帮我们规避风险或者解决风险，这些流程的意义在于帮助我们将风险分类，并提前暴露风险，将风险的范围控制在某个环节，这样我们才能逐个击破，不会手忙脚乱。 2、收集信息在困境二中，我们焦虑的根源在于，我们无法掌控别人的思想和行为，别人的进度、漏洞、困难和风险，对我们来说完全是黑盒，而人越多，这种信息迷雾就越大，因此作为PM我们必须要定期收集足够的信息。我们可以每天组织站会，通常是早上或是晚上，收集各个模块一天的进度和风险。这个进度不仅仅只是一个百分比，还应该细化到完成了哪些功能点。而风险也不应当只抛出问题，还需要给出当前解决进展如何，预计什么时候能解决，还需要什么资源。不过很多时候我们收集到的进度和风险可能是不真实的，还需要我们通过其他途径去识别和确认，例如看一看各模块的代码行数、自测用例通过数、dev环境发布频率跟工作量、进度是否匹配；例如你知道某模块资源紧张，多个项目并行，你可以多关注该模块，自己试一试该模块的功能有没有通，通过其他团队打听该模块的联调进度；又或者通过监控平台扒一扒dev环境核心接口的链路等等。 3、应对风险发现风险后就需要去解决，风险在我看来主要分为需求变更、功能无法实现和延期三个方面。 3.1、需求变更在困境五中提到过，需求变更也分为产品发起的和上游研发发起的。 对于产品发起的需求变更，我们需要评估变更的必要性，主要关注两点：不变更是否影响业务流程的完整性；是否影响业务核心指标，如果必要性不大，我们就要考虑拒绝本次变更，放到后期迭代中去做。 对于上游研发发起的，通常都比较棘手并且解决方式有限，对于不做就一定会影响业务完整性的变更，无非就是协调团队加人并对改动的需求进行重新评审并确认影响面（当然这类需求变更我想没有必要太正式的评审，最重要的是涉及的各团队达成一致并确认好影响面）。确实协调不了人力的则需要考虑是否有更简单的替代方案来实现，不过通常替代方法都不太优雅，要么不符合当下架构的思想，要么不易于扩展，所以通常只能作为临时方案。在达成一致使用临时方案时，也应该和涉及模块的负责人沟通确认好正式方案改造的排期并制定action跟进 3.2、功能无法实现进入开发之后发现功能无法实现这并不常见，但也会出现，这取决于前期评估是否充分。当出现这类问题时，还是要去考虑有没有替代方案，包括技术层面和业务层面的替代方案 3.3、延期延期是最常见的风险，主要出现在提测和上线环节。 对于提测延期，首先看是否能协调研发人力，尽可能保证如期提测，经协调依然无法提测的，则跟测试确认是否能够压缩测试时间，如果不能的则再考虑分批提测，先保证主流程能如期提测，分支流程或页面细节可以安排第二期提测。 对于上线延期，需要先关注问题的根结是什么，不过整体思路跟提测延期是类似的。如果是因为测试进度落后，先协调测试人力，协调后依然无法如期上线的，则需要跟业务产品沟通是否能延期上线，如果不能延期上线，只能考虑能否分批上线，但这通常也伴随着风险，这意味着需要将第二批上线的内容从当前分支上移除或加上开关并保持关闭，这类改动有可能会影响原有流程，也需要测试进行验证。如果是因为测试阶段发现代码&#x2F;方案存在较大漏洞，需要大改的，我想可能没有太好的解决方法，只能与业务产品沟通延期。 总的来说，延期是一类常见且棘手的风险，当延期风险出现后，我们可行的手段都比较有限，因此在前期评估、设计阶段要尽可能的充分，来降低延期出现的可能 4、固定干系人责任，减少交接成本困境三的根源在于干系人责任不明确，或者由于人员变动产生交接，重新对接往往会带来不小的成本，因此在项目前期确定好各模块干系人之后，可以微调模块内的开发分工，但应该尽可能不去调整模块的owner。各模块可能会有多个开发，模块内的功能也被分到不同的开发去对接实现，这也很正常，但是对接过程中产生的一些重大问题，owner应该能去收口，当然这并不是要求owner解决一切，而是owner应该知晓问题、跟进问题、推进问题的解决，至于问题的解决还是应该由引起问题的人去做，权责分明，界限清晰，才能让成员负起责任，否则一定会有人抱有“反正有人兜底，我慢慢做”的想法。 5、好的技术方案设计与项目管理相辅相成很多人会在进入方案设计的阶段才开始重视方案的重要性，不过到这个阶段我们可能已经错过了一些事情。在一些复杂的项目中，我们可能需要提前去做设计，例如在业务提出想法时、在产品输出prd前。因为复杂的项目技术方案往往影响着业务、产品方案的走向，如果业务方案、产品方案评审结束后我们才开始做技术方案设计，可能会发现业务的想法无法实现，或者无法通过优雅的方式实现，那这时作为PM你能选的只有两条路：1、与业务、产品沟通，调整业务方案，显然业务和产品大多数时候都很难接受这种做法，也许你提出的改动会影响业务的核心kpi；2、与开发沟通，用不太优雅的方式实现，虽然很多时候开发最终会妥协，毕竟把项目推上线是最重要的，但这样做往往会给后期迭代留下很大的坑，最终需要不断地向不优雅的方案妥协，代码也会迅速腐化。因此作为PM&#x2F;架构师，我们必须重视技术方案的作用，在项目前期多与业务交流，并同步开始技术方案（这个时候往往只是概要设计）初稿的设计。 6、树立规范才能稳步推进同样的，对于规范，很多时候我们常常在进入开发阶段后才会重视起来，但其实规范也贯穿着整个项目流程，大到项目流程的规范，小到交流话术的规范；从需求文档、技术方案的格式（当然需求文档的规范往往不是PM就能决定的，但我们应当起到推动作用，下面在复盘中会讲到），到工程代码规范，再到上线方案的规范。 文档的规范其实在上面的评审章节有提到过，其实对于文档规范没有过多可以赘述的，不同的行业适用的文档格式可能也不尽相同，不过最重要的是，在一个项目中，同一类型的文档格式规范应当统一，这样同一角色对接起来才能更迅速。当然如果PM时间比较充裕，也可以检查一下这些格式，当然如果你的团队有sop的角色，可以由他来跟进这些规范。 工程代码的规范上面也提到过。工程的规范同一项目的各团队应当尽量保持一致，例如系统命名，系统拆分定位（例如我之前的团队要求对客户端提供接口的应用以-app结尾，仅提供rpc接口的以-service结尾，后台以-admin结尾）、接口设计（比如提供出去的接口出参应该有统一的结构，包、接口的命名分割应该一致）等等。代码的规范可能由于系统的定位不同有所差异，但应当有一个基线标准（在我看来阿里代码规范应该成为基线），各团队在基线只上定制（例如特殊的分层结构，特殊框架的用法等等）。 这里还提到了一个很细微的点——交流话术的规范，当然这不是要求我们说每一句话都要套一个模板，我认为这一点有两层含义。 第一点，当我们在项目中遇到难以解决的问题、重要的告知事项时，应该采用有组织的语言，例如遇到了某个问题无法解决需要求助上级，我们应该明确罗列出问题的背景现状、尝试过的方案、当前的阻塞点、期望诉求等等；又或者你发现了一个改动点可能影响到多个团队，需要他们共同评估影响面，你也应该罗列出改动点、需要评估的点、截止时间等等。有组织的语言通常能帮助我们提高交流效率，减少理解误差，不过通常这不是什么太硬性的要求，不需要一个固定的模板，有组织即可。当然如果你遇到一些不太擅长总结的同事，提出的问题让你难以理解，那么你就应该罗列出你关注的维度，让他按这些维度重新组织语言。 第二点，统一术语，如果你了解过领域驱动设计，你肯定听说过这个说法。同样一个词，在不同团队中由于视角不一致或者是习惯不一致，可能代指着不同的东西（我曾遇到过“附加费”一词在不同团队代指不同费用而引起的线上问题），因此在项目前期，我们有必要建立统一的语言，产品层面需要在需求文档中对一些术语进行准确的定义，研发层面则应当对领域模型和模型中概念统一名称，目的在于消除多义、歧义的描述。此外，研发跟产品之间也应该打破语言的隔阂，举个例子，很多app会有积分的概念，这个积分可能经过了多次迭代，比如原先叫积分改版后叫成长点，那么在业务和产品的口中就一定会称之为积分和成长点，但在研发口中，可能被叫做积分1.0和积分2.0，而这两版的积分底层可能是用的同一张表——通用积分表，这样的语言交流起来会非常的费劲，总是需要映射翻译，对新人也十分不友好，因此研发应该统一语言，用业务产品能理解的方式——积分和成长点来交流，但同时，产品也应该知道一些研发的术语，起码应该知道积分和成长点都是一种通用积分。 7、一切结论落到文档不管是评审过程中遇到的问题和对应的结论，还是新增的需求变更，又或者是其他团队给出的流程梳理，都应该落到相应的文档或项目空间或贴如项目群公告中，再不济也应当是一段话的描述发到项目群中，并艾特相关人。 总之，我们做的一切改动，都应当有迹可循。一方面，人心险恶，尽管不常见，但确实会有人因为逃避责任否认自己曾经说过的话；另一方面，也借此督促项目成员“谨言”，作为PM也好，作为项目一员也好，我们公布出去的每一个结论，都应该是经过查证确认的，我们也应当为自己的结论负责（曾经我就因为一个口误让对接方误解而得到了一个线上bug，因此我深有感悟）。 8、复盘——建立有效的反馈机制我曾经的领导说过一句这样的话：“人一定是会犯错的，我们只能通过机制去约束人，尽可能的防范错误”，对此我十分认同。在一个项目中，我们不可能不犯任何的错误，但最重要的是要学会吸取教训，项目管理机制不可能是一下子就能建成的，因此我们要在犯错中不断总结完善，推动项目机制的完善，同时也提醒我们自己有哪些错误容易犯。 因此在项目成功上线后，我们有必要去做复盘总结项目中的过错，并反向推动流程的完善。我们可以集思广益，征集各个项目成员的想法，罗列项目中存在的问题，并在复盘会上讨论出解决方案，同时将解决方案的责任落实到团队或个人，并指定期限，并跟进进度，从而推动流程优化。当然有的时候项目中也会存在值得固化的亮点，不过鉴于互联网软件项目的复杂性，我觉得只有少部分项目能做到这一点，因此我想这不是一个必须项，对于大多数项目，我们得先做到“无过便是功”。 此外，复盘的过程也是一种双向改进，大多数时候，业务和产品关注研发的交付质量，这通常是比较容易评估的，但同时，研发也会关注业务产品的需求质量，是否条理清晰，易懂无歧义，这往往难以量化，因此复盘对于研发来说，是一个比较好的机会，提出业务与产品的问题，推动需求质量的改进。 四、总结4.1、一些残酷的事实事情永远不会像你想象的那么顺利尽管有这么多的流程、手段来促进项目的成功，并且你做足了充分的准备，项目成员也万般的配合，你也不能指望项目过程中不会出现问题，就如墨菲定律说的“任何可能出错的事情最终都会出错”，PM应该始终保持对风险敏锐的嗅觉，万万不可以抱着“这个项目看起来很简单，一定能正常上线的”想法。 PM总是背锅侠PM往往是吃力不讨好的角色，作为项目最直接的负责人，无论是在项目过程中，还是在项目上线后出现线上问题，这些锅往往会先甩到PM这里，虽然这不意味着PM什么锅都得背，但划分责任也是件麻烦的事情，并且很多时候也难逃一个次要责任 4.2、一些原则不做老好人尽管PM对项目负有最重的责任，但并不意味着PM要做老好人，对各个角色提出的诉求可以一味的答应。PM应该对项目负责而非对个人负责，不需要讨项目成员的欢心，因此当有人提出一些不合理的、难以实现的要求时，应当及时拒绝；又或者当某个模块的成员无法按照要求完成工作时，也应该及时告知他们的负责人。 善于寻求帮助没有人是全面的，并且通常出于职级、权力的限制，很多事情我们自己无法决定，因此有必要及时寻求上级的帮助。无论是评审阶段的分歧，还是方案设计中的难点，又或是延期风险，当我们的能力和权力都不足以解决的时候，及时上报给上级 流程至上如果我们的团队已经现行了一套完善的项目管理流程，那我们应该尽可能按流程执行，并做相应的记录，一方面是对我们自己和团队的保护，另一方面按照流程执行也有助于后期复盘与流程优化 4.3、一些碎碎念勇于反思项目管理能力的不足，通常都会在项目过程中一个个暴露出来，我们不能等到项目结束后复盘时再做总结和反思，当我们发现事情远离预想，风险不断暴露的时候，我们就应该及时反思，调整方向，当然，当局者迷，求助上级并不丢人 保持良好的心态曾经我在带某个项目时，由于时间紧张、prd不完善以及带项目经验不足，每天加完班回去睡觉也会梦见第二天要安排什么工作，心态临近崩溃。后来想想，这样的焦灼属实太过，越是困难就越应该保持理性。当然良好的心态也需要这些困难来不断地磨炼","tags":["项目管理","流程规范"]},{"title":"一些代码规范总结","path":"/2024/08/30/一些代码规范总结/","content":"代码命名： 1、命名应当简介直观，好的命名不需要注释（当然并不是鼓励你不写注释，而是好的命名应当能一眼看出含义或通过一次查询便能明白其含义，注释应当侧重于解释而不是翻译），尽量不适用拼音缩写案例：好的命名：OrderItem（订单项）、FeeItem（费用项）、payMode（支付方式）；坏的命名：ddx、fyx、zffs、OItem、FItem、payFs 2、命名应当表达准确，不应该词不达意案例：我在项目中看到过一个真实的反例，字段名叫companyIdStr，但其实里面存放的是companyName，接手的人会难以理解 3、命名应当尽可能的为以后留出扩展空间案例：例如你的订单现在只有线上支付和线下支付两种支付方式，但仍应该用字段payMode（支付方式）来表达该区别，而不是使用isOfflinePay（是否线下支付）这类命名，也许后面还会出好友代付、扫码支付等方式 4、方法&#x2F;接口名应该与方法的实现一致，例如你的方法叫做queryOrder，那么方法实现中就不应该出现任何更新动作 异常处理 1、流量入口层应当捕获所有异常，并转换为对客提示或外部可识别的异常码，避免底层异常信息直接透出 2、应当自定义一个业务异常类，来和jvm抛出的异常区分 3、捕获到jvm抛出的异常，必须打印堆栈，避免异常信息丢失 日志打印 1、日志中不应当包含大对象，通常只打印关键信息即可案例：log.info(“订单冻结无法操作，order&#x3D;{}”, order);只需打印orderId，不应该把整个order对象打出来（当然如果你的order根本没有操作日志，无法验证发生错误时是否真的冻结，或无法通过数据库、监控平台查证其他关键现场，那你确实需要打出完整的信息） 2、凡是手动抛出异常地方，都应该打印日志，异常现场通常留有最关键的信息，例如出错的订单号，异常的订单状态，若在外层捕获异常后再打印日志，可能导致关键信息丢失 3、打印的信息若需要对对象进行get的，应对对象进行判空，避免因日志导致NPE 4、对于缺失链路追踪能力的项目，可以适当在流量入口处打印日志记录入参 枚举与常量 1、代码中不允许出现魔法值（即未经定义的数字、字符串常量），所有常量应该都是用常量字段或枚举 2、与外部系统交互的接口的参中不允许使用枚举字段，若服务提供方和调用方使用的枚举版本不一致，调用时可能引起序列化异常 代码结构 1、应当尽可能的减少循环和if&#x2F;else的层数，推荐不超过三层，有时可以使用相反的条件提前结束循环或判断案例： 1234567891011121314151617181920// 不推荐的写法for (Order order : orders) &#123;\tif (order.isDeal()) &#123; // ...处理订单已成交逻辑 if (order.isDirectOrder) &#123; // ...处理直营订单逻辑 &#125;\t&#125;&#125;// 推荐的写法，按下面的方式就可以将三层的结构简化为两层for (Order order : orders) &#123;\tif (!order.isDeal()) &#123; continue;\t&#125;\t// ...处理订单已成交逻辑\tif (!order.isDirectOrder) &#123; continue;\t&#125;\t// ...处理直营订单逻辑&#125; 2、方法不宜过长，避免平铺直叙，应当做一些适当的抽象和编排；大多数业务代码可以总结为数据准备、前置校验、前置处理、核心动作（例如扭转订单动作、调用外部接口等）、后置处理（例如确认处理结果、将结果通知外部系统、反写流水状态等等），按照这种方式抽象代码会显得更优雅易懂案例以下是随手写的一个简化的费用退款的案例，实际的费用退款可能复杂的多，可能涉及到重复发起校验、分布式事务等问题，在这里不做讨论，只关注代码结构即可 12345678910111213141516171819202122232425262728293031323334353637383940414243// 退还费用public void refundFee(FeeRefundRequest request) &#123;\t// 数据准备，查询订单信息、用户信息、商品信息、费用信息、流水信息，并组装到context中，省略实现\tFeeRefundContext context = buildContext(request);\t// 前置校验\tpreValidate(context);\t// 前置处理，创建流水，将费用状态更新到退款中\tpreProcess(context);\t// 核心动作，通知银行发起退款，省略实现\tResult result = startRefund(context);\t// 后置处理，确认银行受理结果，反写流水通知用户手里结果\tpostProcess(context, result);&#125;private void preValidate(FeeRefundContext context) &#123;\t// 校验订单状态\tvalidateOrderState(context);\t// 校验费用状态\tvalidateFeeCanRefund(context);&#125;private void preProcess(FeeRefundContext context) &#123;\t// 将费用状态更新到退款中\tupdateFeeState(context.getFeeId(), FeeState.Refunding.getCode());\t// 创建退款流水\tcreateRefundFlow(context);\t// 刷新上下文\trefreshContext(context);&#125;private void postProcess(FeeRefundContext context, Result result) &#123;\tif (result.isAccept) &#123; // 更新流水状态到受理成功 updateFeeFlowState(context.getFlowId, FlowState.Accepted.getCode()); // 发送push通知 sendFeeRefundingPush(context);\t&#125; else &#123; // 回滚到已支付 updateFeeState(context.getFeeId(), FeeState.Paid.getCode()); // 将流水置为失败 updateFeeFlow(context.getFlowId(), FlowState.Failed.getCode());\t&#125;&#125; 代码分层 1、简单的项目通常直接分成controller、server、dao几个简单的层，复杂的项目应该按照需求增加一些抽象，抽离出通用逻辑，例如领域服务domainService、通用业务组件component等 2、层与层之间职责应当隔离，例如controller、dao层不应该处理业务逻辑，service层不应该直接操作数据库等。不过通常靠人力来维护这一点十分困难，难免会出现新手开发者搞乱调用层次，必要的时候可以重要的层拆分成Module，让上层引用下层的依赖，这样如果下层引用上层就会出现循环依赖无法编译 3、层的粒度应当随调用链而减小，即应避免出现同层之间调用、下层调用上层的情况 4、需要调用外部系统的，应当设立一层防腐层，来屏蔽外部系统的模型和异常，即将外部系统的dto转换成内部的领域模型，捕获失败和异常的场景转换为内部可识别的异常案例: 1234567891011121314151617181920@Componentpublic class OrderRepoImpl implement OrderRepo &#123;\t@Autowired\tprivate OrderFacade orderFacade;\t@Autowired\tprivate OrderConverter orderConverter; @Override\tpublic Order queryOrder(Long orderId) &#123; try &#123; Result&lt;OrderDTO&gt; result = orderFacade.queryOrderById(orderId); if (result == null || !result.isSuccess()) &#123; throw new BusiException(&quot;query order by id error&quot;); &#125; return orderConverter.toDo(result.getData); &#125; catch(Exception e) &#123; throw new BusiException(&quot;query order by id error&quot;); &#125;\t&#125;&#125; 数据库操作 1、应当尽量避免连表查询，一方面连表查询可能带来性能问题，另一方面连表查询可能导致一张表的查询逻辑分散在多个Mapper中，当该表结构发生变化时需要修改多处，难以维护 2、如果系统直连数据库，推荐在Mapper外层再包一层防腐层，来屏蔽数据库异常或将PO转换为DO 3、若数据库有主从的，核心场景（例如涉及资金流状态、权益发放状态、库存扣减的场景等）应当查询主库；若存在更新某一条数据后需要将该条数据再查询出来的，应当查询主库；涉及异步回调的，在处理回调数据时优先查询主库（例如监听到支付成功回调后需要将支付数据查出来用于其他流程，此时应优先查主库）。对实时性要求不高的场景、qps高的场景，应避免直接查询主库或过滤后查询主库，并做好限流，防止对主库带来压力","tags":["流程规范","代码规范"]},{"title":"docker安装elasticsearch和kibana","path":"/2024/08/08/docker安装elasticsearch和kibana/","content":"一、安装elasticsearch1、拉取镜像1docker pull elasticsearch:7.17.1 2、启动elasticsearch容器123456[root@VM-4-2-centos ~]# \\&gt; docker run -d --name elasticsearch \\&gt; -p 9200:9200 -p 9300:9300 \\&gt; -e &quot;discovery.type=single-node&quot; \\&gt; -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; \\&gt; elasticsearch:7.17.1 3、将容器内的文件拷贝到本地并删除容器1234docker cp elasticsearch:/usr/share/elasticsearch/config /usr/local/elasticsearchdocker cp elasticsearch:/usr/share/elasticsearch/logs /usr/local/elasticsearchdocker cp elasticsearch:/usr/share/elasticsearch/data /usr/local/elasticsearchdocker cp elasticsearch:/usr/share/elasticsearch/plugins ./ 4、编辑&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config&#x2F;elasticsearch.yml123456cluster.name: &quot;docker-cluster&quot;network.host: 0.0.0.0# 跨域http.cors.allow-origin: &quot;*&quot;http.cors.enabled: truehttp.cors.allow-headers: Authorization,X-Requested-With,Content-Length,Content-Type 5、重新创建容器并挂载文件12345678910[root@VM-4-2-centos config]# \\&gt; docker run -d --name elasticsearch \\&gt; -p 9200:9200 -p 9300:9300 \\&gt; -e &quot;discovery.type=single-node&quot; \\&gt; -e ES_JAVA_OPTS=&quot;-Xms256m -Xmx256m&quot; \\&gt; -v /usr/local/elasticsearch/logs:/usr/share/elasticsearch/logs \\&gt; -v /usr/local/elasticsearch/data:/usr/share/elasticsearch/data \\&gt; -v /usr/local/elasticsearch/plugins:/usr/share/elasticsearch\\plugins \\&gt; -v /usr/local/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\&gt; elasticsearch:7.17.1 访问9200端口返回以下内容则说明启动成功 1234567891011121314151617&#123; &quot;name&quot; : &quot;650773117ec3&quot;, &quot;cluster_name&quot; : &quot;docker-cluster&quot;, &quot;cluster_uuid&quot; : &quot;vMPJ4XvJQmi6YSCpWyZjWA&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;7.17.1&quot;, &quot;build_flavor&quot; : &quot;default&quot;, &quot;build_type&quot; : &quot;docker&quot;, &quot;build_hash&quot; : &quot;e5acb99f822233d62d6444ce45a4543dc1c8059a&quot;, &quot;build_date&quot; : &quot;2022-02-23T22:20:54.153567231Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;8.11.1&quot;, &quot;minimum_wire_compatibility_version&quot; : &quot;6.8.0&quot;, &quot;minimum_index_compatibility_version&quot; : &quot;6.0.0-beta1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125; 1[root@VM-4-2-centos ~]# docker run -d --name kibana -p 5601:5601 kibana:7.17.1 6、设置elasticsearch账号密码先在elasticsearch.yml中添加以下配置并重启容器 12xpack.security.enabled: true xpack.license.self_generated.type: basic xpack.security.transport.ssl.enabled: true 进入到容器并运行elasticsearch-setup-passwords，按照指示开始设置密码，需要为elastic、apm_system、kibana_system、logstash_system、beats_system、remote_monitoring_user六个用户设置密码 123456789101112131415161718192021222324[root@VM-4-2-centos config]# docker exec -it elasticsearch /bin/bashroot@650773117ec3:/usr/share/elasticsearch# ./bin/elasticsearch-setup-passwords interactiveInitiating the setup of passwords for reserved users elastic,apm_system,kibana,kibana_system,logstash_system,beats_system,remote_monitoring_user.You will be prompted to enter passwords as the process progresses.Please confirm that you would like to continue [y/N]yEnter password for [elastic]: Reenter password for [elastic]: Enter password for [apm_system]: Reenter password for [apm_system]: Enter password for [kibana_system]: Reenter password for [kibana_system]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Enter password for [beats_system]: Reenter password for [beats_system]: Enter password for [remote_monitoring_user]: Reenter password for [remote_monitoring_user]: Changed password for user [apm_system]Changed password for user [kibana_system]Changed password for user [kibana]Changed password for user [logstash_system]Changed password for user [beats_system]Changed password for user [remote_monitoring_user]Changed password for user [elastic] 设置好后再次访问9200端口会发现需要输入用户名密码，输入刚刚设置的密码即可访问![[Pasted image 20240808232252.png]] 二、安装kibana1、拉取镜像1docker pull kibana:7.17.1 2、启动kibana容器1[root@VM-4-2-centos ~]# docker run -d --name kibana -p 5601:5601 kibana:7.17.1 3、启动成功后将config目录拷贝到本地并删除容器1[root@VM-4-2-centos kibana]# docker cp kibana:/usr/share/kibana/config /usr/local/kibana/ 4、编辑&#x2F;usr&#x2F;local&#x2F;kibana&#x2F;kibana.yml1234567server.host: &quot;0.0.0.0&quot;server.shutdownTimeout: &quot;5s&quot;elasticsearch.hosts: [ &quot;http://localhost:9200&quot; ]monitoring.ui.container.elasticsearch.enabled: truei18n.locale: &quot;zh-CN&quot;elasticsearch.username: elasticelasticsearch.password: &quot;123456&quot; 5、重新启动kibana1234[root@VM-4-2-centos config]# \\&gt; docker run -d --name kibana -p 5601:5601 \\&gt; -v /usr/local/kibana/config:/usr/share/kibana/config \\&gt; kibana:7.17.1 访问5061端口即可进入kibana"},{"title":"docker安装nacos并配置持久化","path":"/2024/03/23/docker安装nacos并配置持久化/","content":"拉取nacos镜像 1docker pull nacos/naocs-server 创建数据库和用户 1234567## 创建数据库create database nacos default character set utf8mb4 collate utf8mb4_unicode_ci;## 创建nacos用户create user &#x27;nacos&#x27;@&#x27;%&#x27; identified by &#x27;XXXX&#x27;;## 为nacos用户分配权限grant all privileges on nacos.* to &#x27;nacos&#x27;@&#x27;%&#x27;;flush privileges; 创建config_info表，sql语句见https://github.com/alibaba/nacos/blob/master/config/src/main/resources/META-INF/nacos-db.sql 启动镜像 12345678910111213141516[root@VM-4-2-centos init.d]# \\&gt; docker run -d --name nacos -p 8848:8848 -p 9848:9848 \\&gt; -e MODE=standalone \\ #单体模式启动&gt; -e NACOS_AUTH_ENABLE=true \\ #开启鉴权&gt; -e NACOS.CORE.AUTH.PLUGIN.NACOS.TOKEN.SECRET.KEY=&quot;SecretKeyXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX&quot; \\ #秘钥，需base64加密，且原始长度不少于32位&gt; -e NACOS.CORE.AUTH.SERVER.IDENTITY.KEY=XXXX \\ #绕过鉴权的请求头key&gt; -e NACOS.CORE.AUTH.SERVER.IDENTITY.VALUE=XXXX \\ #绕过鉴权的请求头value&gt; -e JVM_XMS=512m \\&gt; -e JVM_XMX=512m \\&gt; -e SPRING_DATASOURCE_PLATFORM=mysql \\&gt; -e MYSQL_SERVICE_HOST=172.17.0.2 \\&gt; -e MYSQL_SERVICE_PORT=3306 \\&gt; -e MYSQL_SERVICE_DB_NAME=nacos \\&gt; -e MYSQL_SERVICE_USER=nacos \\&gt; -e MYSQL_SERVICE_PASSWORD=XXXX \\&gt; -v /usr/local/nacos/logs:/home/nacos/logs/ nacos/nacos-server","tags":["Java","nacos"]},{"title":"springboot自动装配","path":"/2024/03/10/springboot自动装配/","content":"1、自动装配原理我们直接来看看Spring boot的核心注解 1234567891011121314151617@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;) public @interface SpringBootApplication &#123; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;; String[] scanBasePackages() default &#123;&#125;; Class&lt;?&gt;[] scanBasePackageClasses() default &#123;&#125;; Class&lt;? extends BeanNameGenerator&gt; nameGenerator() default BeanNameGenerator.class; boolean proxyBeanMethods() default true; &#125; 可以看到@SpringBootApplication主要由@SpringBootConfiguration 、@EnableAutoConfiguration和@ComponentScan。其中@SpringBootConfiguration是对@Configuration的包装，@ComponentScan用于配置包扫描路径，而@EnableAutoConfiguration则是自动装配的核心 1234567891011@Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) @Documented @Inherited @AutoConfigurationPackage @Import(AutoConfigurationImportSelector.class) public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = &quot;spring.boot.enableautoconfiguration&quot;; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; @EnableAutoConfiguration由@AutoConfigurationPackage和@Import组成，@AutoConfigurationPackage用于指定自动装配的路径，不指定则以当前类所在路径进行扫描；@Import则用于在配置类中引入其他配置类，以将它们的配置信息合并到当前配置类中。@Import有四种用法，包括引入配置类、普通类、ImportSelector 实现类和ImportBeanDefinitionRegistrar 实现类。可以看到在@EnableAutoConfiguration通过@Import引入了AutoConfigurationImportSelector类，可以看到该类实现了ImportSelector接口，Spring在加载时会去扫描@import中引入的ImportSelector并执行ImportSelector#selectImports方法 Pasted image 20240310115831.png 因此我们来看看AutoConfigurationImportSelector.selectImports的实现 12345678@Override public String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations()); &#125; 首先检查自动装配是否开启，未开启则直接返回一个空数组。重点在于getAutoConfigurationEntry方法 1234567891011121314protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); configurations = removeDuplicates(configurations); Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = getConfigurationClassFilter().filter(configurations); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions); &#125; 我们不妨来调试以下看看，新建一个springboot项目，且不额外引入任何依赖，可以发现执行getCandidateConfigurations方法后得到了若干个AutoConfiguration类的全限定名 Pasted image 20240310134909.png 这些类名是从哪里来的呢，我们可以看下getCandidateConfigurations方法的实现。从该方法打印的日志可以看出，这些类名是从META-INF&#x2F;spring.factories中读取的 1234567protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, &quot;No auto configuration classes found in META-INF/spring.factories. If you &quot; + &quot;are using a custom packaging, make sure that file is correct.&quot;); return configurations; &#125; 进入到SpringFactoriesLoader.loadFactoryNames方法中，可以看到通过loadSpringFactories方法取到了一个map，这个map中存放着所有META-INF&#x2F;spring.factories文件中的配置信息，并取org.springframework.boot.autoconfigure.EnableAutoConfiguration对应的值进行自动装配 Pasted image 20240310160037.png spring-boot-autoconfigure下的META-INF\\spring.factories文件 Pasted image 20240310161059.png 我们再回到getAutoConfigurationEntry方法中来看这些取到的configurations，会发现这些类名中有很多我们没有引入的依赖，这些配置类也会执行吗 Pasted image 20240310151912.png 我们先继续向下执行，首先removeDuplicates方法会去除掉重复的配置项，getExclusions方法则会取到@EnableAutoConfiguration注解中exclude和excludeName属性配置的需要排除的配置项（由于我没有配置，这里数量没有变化），重点在于getConfigurationClassFilter.filter方法，可以看到在执行完该方法后，configurations中只剩下13个类名了 Pasted image 20240310163503.png 我们随意打开一个类，AopAutoConfiguration，可以看到该类是简单配置类，但打了一个@ConditionalOnProperty注解该注解派生于@Conditional，当ConfigurationClassFilter.filter执行时，会根据配置类上的@Conditional注解决定到底要不要装配该类，例如AopAutoConfiguration当spring.aop.auto设置为true或缺省时需要装配，否则不装配，类似的注解还@ConditionalOnBean（当指定的 Bean 存在时）、@ConditionalOnClass（当指定的类存在于类路径中时）、@ConditionalOnWebApplication（当应用是一个 Web 应用时）等 Pasted image 20240310140648.png 最终通过AutoConfigurationImportSelector.selectImports获取到的配置类，会再通过一些列处理，用于生成BeanDefinition 2、自己实现一个starter新起一个项目命名为spring-boot-demo-starter，pom.xml如下 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;project xmlns=&quot;http://maven.apache.org/POM/4.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd&quot;&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.6.3&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;org.lzsf&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-demo-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;spring-boot-demo-starter&lt;/name&gt; &lt;description&gt;spring-boot-demo-starter&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;8&lt;/java.version&gt; &lt;/properties&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/project&gt; 创建一个DemoProperty类来映射配置文件 123456789101112131415161718192021222324252627package org.lzsf; import org.springframework.boot.context.properties.ConfigurationProperties; @ConfigurationProperties(&quot;org.lzsf.demo&quot;) public class DemoProperty &#123; private boolean enable; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public boolean isEnable() &#123; return enable; &#125; public void setEnable(boolean enable) &#123; this.enable = enable; &#125; &#125; 创建一个用于装配的bean 123456789101112131415161718package org.lzsf; public class DemoModule &#123; private String name; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return &quot;&#123;name=&#x27;&quot; + getName() + &quot;&#x27;&#125;&quot;; &#125; &#125; 创建自动装配配置类DemoAutoConfiguration，并且设置为enable不为false时需要装配 12345678910111213141516171819package org.lzsf; import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty; import org.springframework.boot.context.properties.EnableConfigurationProperties; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; @Configuration @EnableConfigurationProperties(DemoProperty.class) @ConditionalOnProperty(prefix = &quot;org.lzsf.demo&quot;, value = &quot;enable&quot;, havingValue = &quot;true&quot;, matchIfMissing = true) public class DemoAutoConfiguration &#123; @Bean public DemoModule demoModule(DemoProperty demoProperty) &#123; DemoModule demoModule = new DemoModule(); demoModule.setName(demoProperty.getName()); return demoModule; &#125; &#125; 编写spring.factories文件 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ org.lzsf.DemoAutoConfiguration 最执行maven install将该项目打包到本地仓库再创建一个springboot项目，在该项目中引入上面打好的包 1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.lzsf&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-demo-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在application.properties文件中进行配置 12org.lzsf.demo.enable=true org.lzsf.demo.name=DEMO 最后在启动类中尝试取到bean demoModule 123456789@SpringBootApplication public class DemoApplication &#123; public static void main(String[] args) &#123; ConfigurableApplicationContext context = SpringApplication.run(DemoApplication.class, args); System.out.println(context.getBean(&quot;demoModule&quot;)); &#125; &#125; 执行结果可以看到，demoModule已经被自动装配到容器中了 Pasted image 20240310224615.png 如果我们尝试将org.lzsf.demo.enable改为false，再执行，我们会发现执行失败无法取到该bean Pasted image 20240310224736.png","tags":["Java","SpringBoot"]},{"title":"Canal同步mysql数据至rocketMq","path":"/2023/11/18/Canal同步mysql数据至rocketMq/","content":"Canal概述在业务系统中，我们常常需要关注mysql表中某些数据的变化，当数据发生变化时，实时同步到es中，或者触发某些特定流程，因此需要一个工具提供MySQL数据变更的订阅与消费能力我们知道MySQL的binlog可以用于主从同步，在MySQL集群中，slave会向master发送同步请求，master收到请求后会返回binlog对象，slave收到响应后将binlog写入到自己中继日志relay log中，然后再重放relay log中的数据，变更自身的数据阿里的Canal会伪装成MySQL Slave向Master节点发送同步请求，并解析从Master收到的binlog对象 Canal 实践 环境：腾讯云centos7; Docker version 18.06.3-ce; 1、安装并配置Mysql在docker中拉取mysql镜像 1[root@VM-4-2-centos mysql]# docker pull mysql 拉取成功 123[root@VM-4-2-centos mysql]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEmysql latest a3b6608898d6 3 weeks ago 596MB 在本地新建几个目录， 分别存放数据、配置和日志，用于挂载到docker容器中 123[root@VM-4-2-centos /]# mkdir usr/local/mysql/data[root@VM-4-2-centos /]# mkdir usr/local/mysql/conf[root@VM-4-2-centos /]# mkdir usr/local/mysql/log 创建配置文件开启binlog 1vim usr/local/mysql/conf/my.conf 1234567[mysqld]## 设置binlog存储目录log-bin=/var/lib.mysql/mysql-binserver-id=1binlog_format=ROW## 设置binlog过期时间，默认为0永久expire_logs_days=30 启动mysql容器并挂载目录 123456789[root@VM-4-2-centos /]# \\&gt; docker run -d \\&gt; -p 3306:3306 \\&gt; --name mysql8 \\&gt; -v /usr/local/mysql/data:/var/lib/mysql \\&gt; -v /usr/local/mysql/conf:/etc/mysql/conf.d \\&gt; -v /usr/local/mysql/log:/var/log/mysql \\&gt; -e MYSQL_ROOT_PASSWORD=XXXX \\&gt; mysql 参数解释 12345-d ##后台运行-p [宿主端口]:[容器端口] ##端口映射-v [宿主目录]:[容器目录] ##挂载目录--name ##为容器指定一个名字-e ##设置环境变量 查看docker当前运行的容器，可以看到mysql8已经在运行中了 123[root@VM-4-2-centos /]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES22ef1762e562 mysql &quot;docker-entrypoint.s…&quot; 5 minutes ago Up 5 minutes 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp mysql8 进入到mysql容器 12[root@VM-4-2-centos data]# docker exec -it mysql8 /bin/bashbash-4.4# mysql -u root -p 可以看到binlog已经开启了 123456mysql&gt; show variables like &#x27;log_bin&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_bin | ON |+---------------+-------+ 为Canal创建一个mysql账户并分配权限 12345678mysql&gt; CREATE USER canal IDENTIFIED BY &#x27;canal&#x27;;Query OK, 0 rows affected (0.01 sec)mysql&gt; GRANT SELECT, SHOW VIEW, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO &#x27;canal&#x27;@&#x27;%&#x27;;Query OK, 0 rows affected (0.01 sec)mysql&gt; FLUSH PRIVILEGES;Query OK, 0 rows affected (0.00 sec) 创建一张表用于测试 1234567891011mysql&gt; CREATE DATABASE `test`;Query OK, 1 row affected (0.02 sec)mysql&gt; USE `test`;Database changedmysql&gt; CREATE TABLE `user` ( -&gt; `id` BIGINT(20) UNSIGNED NOT NULL AUTO_INCREMENT COMMENT &#x27;user id&#x27;, -&gt; `user_name` VARCHAR(256) NOT NULL COMMENT &#x27;user name&#x27;, -&gt; `password` VARCHAR(256) NOT NULL COMMENT &#x27;password&#x27;, -&gt; PRIMARY KEY(`id`) -&gt; ) ENGINE=InnoDB AUTO_INCREMENT=1 CHARSET=utf8mb4;Query OK, 0 rows affected, 1 warning (0.03 sec) 2、安装并配置rocketMq（单机）拉取rocketMq镜像 1[root@VM-4-2-centos conf]# docker pull rocketmqinc/rocketmq 创建namesrv的文件夹用以挂载 12[root@VM-4-2-centos local]# mkdir /usr/local/rocketmq/namesrv/logs[root@VM-4-2-centos local]# mkdir /usr/local/rocketmq/namesrv/store 启动namesrv 12345678[root@VM-4-2-centos local]# \\&gt; docker run -d \\&gt; -p 9876:9876 \\&gt; -v /usr/local/rocketmq/namesrv/logs:/root/logs \\&gt; -v /usr/local/rocketmq/namesrv/store:/root/store \\&gt; --name rmqNamesrv \\&gt; rocketmqinc/rocketmq \\&gt; sh mqnamesrv 查看运行中的容器可以看到容器已启动 1234[root@VM-4-2-centos local]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESfdb2d77cb29f rocketmqinc/rocketmq &quot;sh mqnamesrv&quot; 9 seconds ago Up 8 seconds 10909/tcp, 0.0.0.0:9876-&gt;9876/tcp, 10911/tcp rmqNamesrv71f35f013ae1 mysql &quot;docker-entrypoint.s…&quot; 35 minutes ago Up 35 minutes 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp mysql8 查看namesrv日志可以看到启动成功了 123[root@VM-4-2-centos local]# cat /usr/local/rocketmq/namesrv/logs/rocketmqlogs/namesrv.log... ...2023-11-19 11:16:18 INFO main - The Name Server boot success. serializeType=JSON 创建broker的文件夹及配置文件用以挂载到容器 1234[root@VM-4-2-centos local]# mkdir /usr/local/rocketmq/broker/logs[root@VM-4-2-centos local]# mkdir /usr/local/rocketmq/broker/store[root@VM-4-2-centos local]# mkdir /usr/local/rocketmq/broker/conf[root@VM-4-2-centos local]# vim /usr/local/rocketmq/broker/conf/broker.conf 12345678910111213141516171819# 所属集群名称，如果节点较多可以配置多个brokerClusterName = DefaultCluster#broker名称，master和slave使用相同的名称，表明他们的主从关系brokerName = broker-a#0表示Master，大于0表示不同的slavebrokerId = 0#表示几点做消息删除动作，默认是凌晨4点deleteWhen = 04#在磁盘上保留消息的时长，单位是小时fileReservedTime = 48#有三个值：SYNC_MASTER，ASYNC_MASTER，SLAVE；同步和异步表示Master和Slave之间同步数据的机制；brokerRole = ASYNC_MASTER#刷盘策略，取值为：ASYNC_FLUSH，SYNC_FLUSH表示同步刷盘和异步刷盘；SYNC_FLUSH消息写入磁盘后才返回成功状态，ASYNC_FLUSH不需要；flushDiskType = ASYNC_FLUSH# 设置namesrv地址namesrvAddr=***.***.***.***:9876# 设置宿主机ip地址brokerIP1=***.***.***.*** 启动broker容器 1234567891011[root@VM-4-2-centos local]# \\&gt; docker run -d \\&gt; -p 10911:10911 -p 10909:10909 \\&gt; -v /usr/local/rocketmq/broker/logs:/root/logs \\&gt; -v /usr/local/rocketmq/broker/store:/root/store \\&gt; -v /usr/local/rocketmq/broker/conf/broker.conf:/opt/rocketmq/conf/broker.conf \\&gt; --name rmqBroker \\&gt; --link rmqNamesrv:namesrv \\&gt; -e &quot;NAMESRV_ADDR=namesrv:9876&quot; \\&gt; rocketmqinc/rocketmq \\&gt; sh mqbroker -c /opt/rocketmq/conf/broker.conf 安装并启动rocketmq-console 12345678[root@VM-4-2-centos rocketmq]# docker pull styletang/rocketmq-console-ng[root@VM-4-2-centos rocketmq]# \\&gt; docker run -d \\&gt; --restart=always \\&gt; --name rocketmqConsole \\&gt; -e &quot;JAVA_OPTS=-Drocketmq.namesrv.addr=***.***.***.***:9876 -Drocketmq.config.isVIPChannel=false&quot; \\&gt; -p 9090:8080 \\&gt; styletang/rocketmq-console-ng 3、配置并启动Canal下载Cancal并解压 123[root@VM-4-2-centos canal]# wget https://github.com/alibaba/canal/releases/download/canal-1.1.7/canal.deployer-1.1.7.tar.gz[root@VM-4-2-centos canal]# mkdir canal-deployer[root@VM-4-2-centos canal]# tar -zxvf canal.example-1.1.7.tar.gz -C ./canal-deployer 更改.&#x2F;canal-deployer&#x2F;conf&#x2F;canal.properties配置，将serverMode改为rocketMq 12# tcp, kafka, rocketMQ, rabbitMQ, pulsarMQcanal.serverMode = rocketMQ 更改.&#x2F;canal-deployer&#x2F;conf&#x2F;example&#x2F;instance.properties配置，其中canal.instance.mysql.slaveId不能与mysql的id相同，1.0.26版本后会自动生成，可不配置 123456789# mysql地址canal.instance.master.address=127.0.0.1:3306# mysql用户canal.instance.dbUsername=canalcanal.instance.dbPassword=canal# 需要监听的库表，默认为所有canal.instance.filter.regex=.*\\\\..*# 打开动态topic，且每个表都会发送到表名的topic中canal.mq.dynamicTopic=.*\\\\..* 启动canal 1[root@VM-4-2-centos bin]# sh /usr/local/canal/canal-deployer/bin/startup.sh 这时候我们在到rocketMq后台可以看到已经有名为test_user的topic 动态生成的topic 我们在test.user中插入一条数据 1234567891011mysql&gt; INSERT INTO `user` (`user_name`, `password`) -&gt; VALUES (&#x27;zhangsan&#x27;, &#x27;zhangsan1234&#x27;);Query OK, 1 row affected (0.01 sec)mysql&gt; SELECT * FROM `user`;+----+-----------+--------------+| id | user_name | password |+----+-----------+--------------+| 1 | zhangsan | zhangsan1234 |+----+-----------+--------------+1 row in set (0.00 sec) mq也收到了该消息 新增消息 再尝试更新一下 123mysql&gt; UPDATE `user` SET `password` = &#x27;zhangsan2345&#x27; WHERE `id` = 1;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0 更新消息","tags":["Java","Canal","MySQL","Binlog","RocketMQ"]}]